{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc585246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 3‑column CSV: incidents_categorized.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Φόρτωση του CSV (άλλαξε τη διαδρομή αν χρειάζεται)\n",
    "df = pd.read_csv('occurrences.csv', sep=';', low_memory=False)\n",
    "\n",
    "# 2. Μετονομασία της στήλης περιγραφής σε 'report'\n",
    "df = df.rename(columns={'Description': 'report'})\n",
    "\n",
    "# 3. Category από Main_Event_L1\n",
    "df['category'] = df['Main_Event_L1']\n",
    "\n",
    "# 4. Severity map σε Low/Medium/High/ Critical\n",
    "severity_map = {\n",
    "    'Less Serious': 'Low',\n",
    "    'Serious': 'Medium',\n",
    "    'Very Serious': 'High',\n",
    "    'Marine Incident': 'Critical'\n",
    "}\n",
    "df['severity'] = df['Occurrence_Severity'].map(severity_map)\n",
    "\n",
    "# 5. Αποθήκευση σε νέο CSV με τις 3 στήλες\n",
    "df[['report', 'category', 'severity']].to_csv('incidents_categorized.csv', index=False)\n",
    "\n",
    "print(\"Prepared 3‑column CSV: incidents_categorized.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054c635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Accident to person(s)         1339\n",
      "Damage / Loss Of Equipment    1095\n",
      "Loss Of Control                557\n",
      "Grounding / Stranding          377\n",
      "Contact                        299\n",
      "Collision                      254\n",
      "Fire / Explosion               234\n",
      "Flooding / Foundering          120\n",
      "Capsizing / Listing             73\n",
      "Non-accidental Event             3\n",
      "Hull Failure                     2\n",
      "Name: count, dtype: int64\n",
      "severity\n",
      "Critical    2480\n",
      "Low         1491\n",
      "Medium       209\n",
      "High         174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Πόσες διαφορετικές κατηγορίες προβλημάτων υπάρχουν;\n",
    "print(df[\"category\"].value_counts())\n",
    " \n",
    "# Πόσες διαφορετικές σοβαρότητες υπάρχουν;\n",
    "print(df[\"severity\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1878060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows: 4353\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Φόρτωση\n",
    "df = pd.read_csv('incidents_categorized.csv')\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "\n",
    "# Έλεγχος\n",
    "print(f\"Remaining rows: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8262c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in category: 0\n",
      "Missing in severity: 0\n"
     ]
    }
   ],
   "source": [
    "# Έλεγχος υπολειπόμενων NaN\n",
    "print(\"Missing in category:\", df['category'].isna().sum())\n",
    "print(\"Missing in severity:\", df['severity'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b68678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Accident to person(s)         1342\n",
      "Damage / Loss Of Equipment    1097\n",
      "Loss Of Control                557\n",
      "Grounding / Stranding          377\n",
      "Contact                        299\n",
      "Collision                      254\n",
      "Fire / Explosion               234\n",
      "Flooding / Foundering          120\n",
      "Capsizing / Listing             73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Hull Failure → Damage / Loss Of Equipment\n",
    "df['category'] = df['category'].replace(\n",
    "    {'Hull Failure': 'Damage / Loss Of Equipment'}\n",
    ")\n",
    "\n",
    "# 2) Non‑accidental Event → Accident to person(s)\n",
    "df['category'] = df['category'].replace(\n",
    "    {'Non-accidental Event': 'Accident to person(s)'}\n",
    ")\n",
    "\n",
    "# Έλεγχος\n",
    "print(df['category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00818176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f49395c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping placeholders: 4311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Αφαίρεση placeholder reports\n",
    "mask = df['report'].str.strip() != \"See MAIB investigation report, when available\"\n",
    "df = df[mask]\n",
    "\n",
    "# (προαιρετικά) Έλεγχος πόσες έμειναν\n",
    "print(\"Rows after dropping placeholders:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139f1e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3017, Val: 647, Test: 647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Stratified split\n",
    "train, temp = train_test_split(df, test_size=0.30, stratify=df['category'], random_state=42)\n",
    "val, test  = train_test_split(temp, test_size=0.50, stratify=temp['category'], random_state=42)\n",
    "\n",
    "# 6) Αποθήκευση\n",
    "train.to_csv('train.csv', index=False)\n",
    "val.  to_csv('val.csv',   index=False)\n",
    "test. to_csv('test.csv',  index=False)\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac689e",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be121fb6",
   "metadata": {},
   "source": [
    "Extraction of the minority samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033f3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "counts = train['category'].value_counts()\n",
    "# Μετά τη συγχώνευση, οι small classes είναι:\n",
    "small_cats = counts[counts < 150].index.tolist()\n",
    "# π.χ. ['Capsizing / Listing','Flooding / Foundering', 'Damage / Loss Of Equipment', ...]\n",
    "minority_df = train[train['category'].isin(small_cats)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e423572",
   "metadata": {},
   "source": [
    "AUGMENTATION IN MERGED CLASSES - METHODS: Back translation, Contextual substitution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b5f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\elena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b8b806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elena\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-fr. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elena\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elena\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elena\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-de-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Back-translation function (μέσω French)\n",
    "def back_translate(text, src=\"en\", mid=\"fr\"):\n",
    "    tok_fwd = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{src}-{mid}')\n",
    "    mdl_fwd = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-{src}-{mid}')\n",
    "    fr = mdl_fwd.generate(**tok_fwd(text, return_tensors=\"pt\", truncation=True))\n",
    "    fr_text = tok_fwd.decode(fr[0], skip_special_tokens=True)\n",
    "    tok_rev = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{mid}-{src}')\n",
    "    mdl_rev = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-{mid}-{src}')\n",
    "    en = mdl_rev.generate(**tok_rev(fr_text, return_tensors=\"pt\", truncation=True))\n",
    "    return tok_rev.decode(en[0], skip_special_tokens=True)\n",
    "\n",
    "# Contextual substitution augmenter\n",
    "aug_ctx = naw.ContextualWordEmbsAug(\n",
    "    model_path=\"distilbert-base-cased\",\n",
    "    action=\"substitute\"\n",
    ")\n",
    "\n",
    "augmented = []\n",
    "for _, row in minority_df.iterrows():\n",
    "    txt = row['report']\n",
    "    cat = row['category']\n",
    "    sev = row['severity']\n",
    "    # π.χ. δύο back-translations + δύο context subs\n",
    "    augmented += [\n",
    "        {\"report\": back_translate(txt, mid=\"fr\"), \"category\": cat, \"severity\": sev},\n",
    "        {\"report\": back_translate(txt, mid=\"de\"), \"category\": cat, \"severity\": sev},\n",
    "        {\"report\": aug_ctx.augment(txt),                \"category\": cat, \"severity\": sev},\n",
    "        {\"report\": aug_ctx.augment(txt),                \"category\": cat, \"severity\": sev},\n",
    "    ]\n",
    "\n",
    "aug_df = pd.DataFrame(augmented)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcce8b",
   "metadata": {},
   "source": [
    "Union of training datasets (old train with augmentated data) & retraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755f74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "balanced_train = pd.concat([train, aug_df], ignore_index=True)\n",
    "balanced_train = balanced_train.sample(frac=1, random_state=42)\n",
    "balanced_train.to_csv(\"train_augmented.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
